{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create data for decision tree\n",
    "\"\"\"\n",
    "def create_data(discrete=False):\n",
    "    feature_name = np.array(['outlook', 'temperature', 'humidity', 'windy'])\n",
    "    continuous_features_index = np.array([1, 2], dtype=np.float32) if not discrete else np.empty((0), dtype=np.float32)\n",
    "    data = np.array([\n",
    "        [1., 85., 85., 0.],\n",
    "        [1., 80., 90., 1.],\n",
    "        [2., 83., 78., 0.],\n",
    "        [3., 70., 96., 0.],\n",
    "        [3., 68., 80., 0.],\n",
    "        [3., 65., 70., 1.],\n",
    "        [2., 64., 65., 1.],\n",
    "        [1., 72., 95., 0.],\n",
    "        [1., 69., 70., 0.],\n",
    "        [3., 75., 80., 0.],\n",
    "        [1., 75., 70., 1.],\n",
    "        [2., 72., 90., 1.],\n",
    "        [2., 81., 75., 0.],\n",
    "        [3., 71., 80., 1.]\n",
    "    ], dtype=np.float32)\n",
    "    if discrete:\n",
    "        data[:, 1][data[:, 1] < 70] = 1.\n",
    "        data[:, 1][np.logical_and(70. <= data[:, 1],data[:, 1] <= 79.)] = 2.\n",
    "        data[:, 1][data[:, 1] >= 80.] = 3.\n",
    "        data[:, 2][data[:, 2] < 76] = 1.\n",
    "        data[:, 2][data[:, 2] >= 76] = 2.\n",
    "    label = np.array([\n",
    "        [0.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [0.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [1.],\n",
    "        [0.]\n",
    "    ], dtype=np.float32)\n",
    "    return data, label, feature_name, continuous_features_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Compute the entropy\n",
    "\"\"\"\n",
    "def get_entropy(x):\n",
    "    distinct_x, count_x = np.unique(np.squeeze(x), return_counts=True)\n",
    "    p = np.divide(count_x, np.sum(count_x))\n",
    "    entropy = -np.sum(np.multiply(p, np.log2(p)))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select the best feature for splitting\n",
    "Return: the index of the best features\n",
    "\"\"\"\n",
    "def get_best_feature(data, label, continuous_features_index):\n",
    "    num_data = data.shape[0]\n",
    "    num_feature = data.shape[1]\n",
    "    base_entropy = get_entropy(label)\n",
    "    information_gain_ratios = np.zeros((num_feature))\n",
    "    best_low_mid_threshold = dict()\n",
    "    best_mid_high_threshold = dict()\n",
    "    best_data = dict()\n",
    "    \n",
    "    #Compute entropy for each feature given#\n",
    "    for i in range(num_feature):\n",
    "        #Dealing with continuous feature#\n",
    "        if i in continuous_features_index:\n",
    "            best_info_gain_ratio = 0.\n",
    "            sorted_unique_values = np.sort(np.unique(data[:, i]))\n",
    "            for j in range(sorted_unique_values.shape[0] - 1):\n",
    "                for k in range(j + 1, sorted_unique_values.shape[0]):\n",
    "                    data_temp = np.copy(data)\n",
    "                    data_temp[:, i][data_temp[:, i] <= sorted_unique_values[j]] = 1.\n",
    "                    data_temp[:, i][np.logical_and(sorted_unique_values[j] < data_temp[:, i], data_temp[:, i] <= sorted_unique_values[k])] = 2.\n",
    "                    data_temp[:, i][data_temp[:, i] > sorted_unique_values[k]] = 3.\n",
    "                    unique_values = np.unique(data_temp[:, i])\n",
    "                    feature_entropy = 0.\n",
    "                    for value in unique_values:\n",
    "                        label_per_value = label[data_temp[:, i] == value]\n",
    "                        p_per_value = label_per_value.shape[0] / num_data\n",
    "                        feature_entropy += p_per_value * get_entropy(label_per_value)\n",
    "                    split = get_entropy(data_temp[:, i])\n",
    "                    inform_gain_ratio = (base_entropy - feature_entropy) / split\n",
    "                    if inform_gain_ratio > best_info_gain_ratio:\n",
    "                        best_info_gain_ratio = inform_gain_ratio\n",
    "                        best_low_mid_threshold[str(i)] = sorted_unique_values[j]\n",
    "                        best_mid_high_threshold[str(i)] = sorted_unique_values[k]\n",
    "                        best_data[str(i)] = np.copy(data_temp)\n",
    "                        \n",
    "        #Dealing with discrete feature#\n",
    "        else:\n",
    "            unique_values = np.unique(data[:, i])\n",
    "            feature_entropy = 0.\n",
    "            for value in unique_values:\n",
    "                label_per_value = label[data[:, i] == value]\n",
    "                p_per_value = label_per_value.shape[0] / num_data\n",
    "                feature_entropy += p_per_value * get_entropy(label_per_value)\n",
    "            split = get_entropy(data[:, i])\n",
    "            information_gain_ratios[i] = (base_entropy - feature_entropy) / split\n",
    "    \n",
    "    #Select the best feature to split the tree#\n",
    "    best_feature_index = np.argmax(information_gain_ratios)\n",
    "    \n",
    "    #Return transformed data according to processed continuous feature#\n",
    "    if best_feature_index in continuous_features_index:\n",
    "        data_transformed = best_data[str(best_feature_index)]\n",
    "        low_mid_threshold = best_low_mid_threshold[str(best_feature_index)]\n",
    "        mid_high_threshold = best_mid_high_threshold[str(best_feature_index)]\n",
    "    else:\n",
    "        data_transformed = data\n",
    "        low_mid_threshold = mid_high_threshold = 0.\n",
    "    return best_feature_index, data_transformed, (low_mid_threshold, mid_high_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create decision tree node\n",
    "\"\"\"\n",
    "def create_treenode(tree, data, label, feature_name, continuous_features_index):\n",
    "    #Check if the data subset of the current node is pure#\n",
    "    if np.unique(label).shape[0] == 1:\n",
    "        return label.reshape(-1)[0]\n",
    "    \n",
    "    #Check if no features are remained#\n",
    "    elif data.shape[1] == 0:\n",
    "        possible_class, counts = np.unique(label, return_counts=True)\n",
    "        return possible_class[np.argmax(counts)]\n",
    "    \n",
    "    #Get the best feature for splitting#\n",
    "    best_index, data_transformed, contin_threshold = get_best_feature(data, label, continuous_features_index)\n",
    "    values = np.unique(data_transformed[:, best_index])\n",
    "    split_feature_name = feature_name[best_index]\n",
    "    \n",
    "    #Update the index of continuous feature and the feature name list#\n",
    "    new_continuous_features_index = np.copy(continuous_features_index)\n",
    "    if best_index in new_continuous_features_index:\n",
    "        new_continuous_features_index = np.setdiff1d(new_continuous_features_index, np.array([best_index], dtype=np.float32))\n",
    "    new_continuous_features_index[best_index <= new_continuous_features_index] -= 1\n",
    "    new_feature_name = np.append(feature_name[0:best_index], feature_name[best_index + 1:])\n",
    "    \n",
    "    #Create the tree#\n",
    "    for value in values:\n",
    "        #Create new data and label for child node#\n",
    "        temp = data_transformed[data_transformed[:, best_index] == value]\n",
    "        new_data = np.append(temp[:, :best_index], temp[:, best_index + 1:], axis=1)\n",
    "        new_label = label[data_transformed[:, best_index] == value]\n",
    "        \n",
    "        #Recursion#\n",
    "        subtree = create_treenode(list(), new_data, new_label, new_feature_name, new_continuous_features_index)\n",
    "        \n",
    "        #Dealing with continuous feature#\n",
    "        if best_index in continuous_features_index:\n",
    "            if value == 1.:\n",
    "                cond_str = '<= {}'.format(contin_threshold[0])\n",
    "            elif value == 2.:\n",
    "                cond_str = '{} <  & <= {}'.format(contin_threshold[0], contin_threshold[1])\n",
    "            else:\n",
    "                cond_str = '{} <'.format(contin_threshold[1])\n",
    "            tree.append(((split_feature_name, cond_str), subtree))\n",
    "        else:\n",
    "            tree.append(((split_feature_name, value), subtree))\n",
    "    return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('outlook', 1.0), [(('humidity', 1.0), 1.0), (('humidity', 2.0), 0.0)]),\n",
       " (('outlook', 2.0), 1.0),\n",
       " (('outlook', 3.0), [(('windy', 0.0), 1.0), (('windy', 1.0), 0.0)])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label, feature_name, continuous_features_index = create_data(discrete=True)\n",
    "tree = create_treenode(list(), data, label, feature_name, continuous_features_index)\n",
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('outlook', 1.0),\n",
       "  [(('windy', 0.0),\n",
       "    [(('temperature', '<= 69.0'), 1.0),\n",
       "     (('temperature', '69.0 <  & <= 85.0'), 0.0)]),\n",
       "   (('windy', 1.0),\n",
       "    [(('temperature', '<= 75.0'), 1.0),\n",
       "     (('temperature', '75.0 <  & <= 80.0'), 0.0)])]),\n",
       " (('outlook', 2.0), 1.0),\n",
       " (('outlook', 3.0), [(('windy', 0.0), 1.0), (('windy', 1.0), 0.0)])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, label, feature_name, continuous_features_index = create_data(discrete=False)\n",
    "tree = create_treenode(list(), data, label, feature_name, continuous_features_index)\n",
    "tree"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
